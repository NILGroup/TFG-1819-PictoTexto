% !TeX encoding = ISO-8859-1


\chapter{Herramientas}
\label{cap:Herramientas}

A lo largo de este capítulo analizaremos las diferentes herramientas utilizadas para el desarrollo de este TFG, lo primero que se requiere es de un espacio donde facilitar la conexión entre los diferentes servicios web para ello utilizamos Django, la función principal de nuestro TFG es realizar un buen uso del lenguaje natural, para ello se necesita un analizador de dicho lenguaje como es Spacy y un generador de frases de lenguaje natural en este caso el elegido es Simple-NLG, para conseguir las traducciones de texto a pictogramas ha sido imprescindible el uso de la API de Arasaac.   
Por último, para agilizar tanto el tiempo de respuesta de los servidores como el proceso de comunicación de los diferentes servicios web de nuestro trabajo se ha elegido la herramienta Angular.
  

%-------------------------------------------------------------
\section{Django}
%-------------------------------------------------------------
\label{cap3:sec:Django}
Debido a los diferentes servicios web que se utilizan en este TFG, se necesita un espacio o contenedor en donde pudieran desembocar y relacionar entre sí estos servicios mencionados anteriormente. Además al ser python uno de los lenguajes de programación más utilizados en el proyecto, era aconsejable que dicho contenedor estuviera también desarrollado en ese mismo lenguaje. 
Con estos requisitos previos se eligió la herramienta Django que al ser un framework de desarrollo web\footnote{https://tutorial.djangogirls.org/es/django/} de código abierto escrito en Python,  y respetando el patrón de diseño conocido como Modelo-Vista-Controlador (M-V-C). Tiene como meta principal facilitar la creación de sitios web. Además de ser muy importante el re-uso de código, la conectividad y el desarrollo rápido.\\
Todos estos motivos la convirtieron en la herramienta ideal sobre la que construir la comunicación entre los diferentes servicios y además al estar escrita en Python nos solucionaba problemas de errores con uno de los lenguajes de programación utilizados. 

\section{API-Arasaac}
%-------------------------------------------------------------
\label{cap3:sec:API-Arasaac}

Dado un pictogrma necesitabamos conocer la palabra asociada a dicho pictograma y para eso hemos utilizado la API de Arasaac \footnote{https://beta.arasaac.org/developers/api}, centrándonos en la sección de pictogramas.
En este trabajo se han utilizado dos de los métodos proporcionados en la API, por un lado obtenemos el texto asociado a un pictograma partiendo de la propia palabra mediante el método(/pictograms/search/{searchText}), gracias a esto se logra una conexión entre el texto, su pictograma y un objeto con toda la información relevante asociada a la palabra , por ejemplo de la palabra \textit{perro} se consigue un objeto con dicha información relativa a la palabra, como puede ser: sus keywords o palabras clave, el tipo de palabra que es, los posibles plurales de dicha palabra, el significado de la misma, etc. 
 
El segundo método (/pictograms/{idPictogram}) es necesario para la parte del buscador de nuestra aplicación, ya que permite obtener la información del pictograma a partir de su id, con esto se consigue una relación entre la palabra y su pictograma gracias al código de identificación.
Siguiendo con el ejemplo anterior, si se desea buscar la palabra \textit{perro}, el método relaciona dicha palabra a su id devolviendo el pictograma asociado a ella, en este caso el id 2517. 

\section{Spacy}
%-------------------------------------------------------------
\label{cap3:sec:Spacy}
Spacy es una biblioteca escrita en Python diseñada para el procesamiento avanzado de lenguaje natural\footnote{\url{https://medium.com/datos-y-ciencia/comenzando-con-spacy-para-procesamiento-de-lenguaje-natural-e8cf24a18a5a}}.

Para el uso del lenguaje natural primero se necesitaba realizar una clasificación del tipo de palabras, es decir, clasificar dichas palabras según sean sustantivos, adjetivos, verbos,etc.
Una vez realizada esa organización se necesita realizar un análisis de los atributos de cada palabra, esto significa que dependiendo del tipo de palabra se conozca su género, número, tiempo verbal, etc.\\ 
Para esta función de análisis se eligió usar la librería Spacy por delante de otras como ClearNLP o CORENLP, esta elección se basó en poder hacer un procesamiento del lenguaje natural en castellano y ademas la precisión y velocidad cuando realiza un análisis de las palabras, como podemos observar en la figura \ref{fig:precisionSpacy} .\\

\figura{Bitmap/Herramientas/precisionSpacy}{width=200px}{fig:precisionSpacy}{Benchmark de diferentes procesadores del lenguaje.}
    
Spacy por tanto será el encargado de proporcionarnos la información de los atributos de cada palabra analizada, mencionados en el párrafo anterior, mediante su función Tokenizer. Así con esta función obtendremos la categoría léxica de las palabras, es decir, conseguiremos conocer si la palabra es sustantivo, adjetivo, verbo, determinante, etc. Una vez conseguida su categoría léxica, Spacy nos proporciona características de cada palabra:
\begin{itemize}
    \item \textbf{Sustantivos} y \textbf{Adjetivos}, la información principal que detalla es muy parecida para ambos, proporcionando: tipo de palabra, género, número, sinónimos de la palabra, keyword o palabra clave.
    \item \textbf{Pronombres}, para los pronombres se obtiene: tipo de palabra, tipo de pronombre, número de la persona y número gramatical.
    \item \textbf{Verbos}, de Spacy se obtiene: tipo de palabra, forma verbal, tiempo verbal, keyword o palabra clave.
    \item \textbf{Determinantes}, la información que detalla es: tipo de palabra, tipo de determinante, género y número.
    \item \textbf{Adverbios}, los atributos que presenta son: tipo de palabra, tipo de adverbio, keyword o palabra clave. 
    \item \textbf{Preposiciones}, nos informa de características tales como: tipo de palabra, keyword o palabra clave.
\end{itemize}

\section{SimpleNLG-ES}
%-------------------------------------------------------------
\label{cap3:sec:SimpleNLG}
Una vez Spacy analiza y clasifica todas las partes de la oración. Se necesita una nueva herramienta que recibiendo como entrada una lista con el análisis pormenorizado de las oraciones e identificados el sujeto, verbo y complementos de las mismas, sea capaz de generar cada palabra en lenguaje natural. 
La herramienta idónea elegida para realizar esta tarea es SimpleNLG-ES, esta biblioteca hecha en Java permite realizar la generación de lenguaje natural usando palabras\citep{Trzpis2015}.\\
Conforme los datos de entrada que reciba Simple-NLG es capaz de crear diferentes tipos de frases, yendo desde frases simples o nominales hasta aquellas que posean un cierto grado de complejidad como pueden ser frases más complejas u oraciones. Dependiendo la complejidad de la frase, su forma de realizar la generación de lenguaje natural difiere una de otra.
\begin{itemize}
    \item \textbf{Frases simples o nominales}. Cuando se ha identificado que la frase para analizar no tiene ningún verbo, Simple-NLG empieza a generar el sustantivo de la frase añadiendo a dicho sustantivo el determinante que concuerde con el género y número especificado en los datos de entrada, en caso que fuera necesario. Una vez creado el sustantivo con su determinante correspondiente Simple-NLG irá generando los complementos que integran el sujeto completo, como pueden ser: adjetivos, adverbios, etc. Por ejemplo para la frase ``La casa roja''. El sustantivo será ``casa'', su determinante asociado será ``la'' y por último el complemento del sustantivo será ``roja''.    
    \item \textbf{Frases compuestas u Oraciones}. Para este tipos de frases u oraciones lo primero que se busca es el verbo, una vez identificado dicho verbo, aquello que se encuentre delante de él formará el sujeto y el resto será el predicado con sus complementos, haciendo la generación del lenguaje en esta ocasión de la siguiente manera:
    \begin{itemize}
    \item Sujeto. Se genera de la misma forma que en las frases nominales, por ejemplo ``mi perro''.
    \item Verbo. Dependiendo de los datos de entrada recibidos, se obtiene la forma y el tiempo verbal, diferenciando entre pasado, futuro o presente, este último a su vez es el que viene por defecto. Y generando así la respuesta más adecuada. Como por ejemplo ``es'' se generará como una oración en presente. 
    \item Complementos. Una vez generado el verbo se identifica si existen más datos en el predicado, en caso afirmativo se generan los elementos correspondientes. Por ejemplo ``negro''. 
    \end{itemize}
\end{itemize}
Es importante destacar que Simple-NLG permite también negar las frases u oraciones, y además una vez se haya realizado la generación de la frase al completo, siguiendo el ejemplo anteriormente dado, la frase generada en su totalidad será: ``mi perro es negro''. \\
La misma herramienta se encargará de devolver la respuesta del servicio web gracias a la última fase llamada realización.
    
\section{Angular}
%-------------------------------------------------------------
\label{cap3:sec:Angular}
El motivo principal por el que se ha decidido utilizar la herramienta Angular es el de dotar de una mayor rapidez a nuestra aplicación. 
Angular es un framework de desarrollo creado y mantenido por Google, cuya finalidad consiste en el desarrollo de aplicaciones web SPA (Single-Page Applications), es decir, interacción web con una sola página web, lo que provoca que la aplicación sea más rápida, dinámica y fluida. 
Angular se encargará del lado frontend de la aplicación haciendo cada parte de la página web independiente. 
  
Para realizar la parte frontend de nuestra aplicación se estudiaron las diferentes herramientas que se podrían utilizar, en un primer momento se pensó en extender la herramienta Django para la parte del cliente, pero dicha herramienta ofrecía ciertas limitaciones en esta parte, por tanto se descartó esa idea.
La segunda alternativa fue la opción de introducir JQuery, esta segunda opción tampoco era la más idónea ya que se trata de una librería orientada a acceder y modificar los elementos de la página y no para gestionar el uso de diferentes servicios, algo esencial en este proyecto.
La última opción y al final la escogida fue la de implantar dentro de nuestro trabajo Angular, ya que era la alternativa que más funcionalidades aportaba y de las analizadas la más orientada a gestionar diferentes servicios en una misma página.
Además la herramienta está formado por diferentes módulos distintos unos de otros y estos a su vez están formados por diferentes componentes, ofreciendo una división automática del código para que los usuarios solo carguen aquellas componentes que necesitan nuestro proyecto se han creado dos totalmente independientes como puede ser el buscador de pictogramas o el componente de traductor de pictogramas, estos dos módulos se podrían integrar por separado en cualquier otra aplicación.

 


