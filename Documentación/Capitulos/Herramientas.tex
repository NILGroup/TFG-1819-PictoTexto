% !TeX encoding = ISO-8859-1


\chapter{Herramientas}
\label{cap:Herramientas}

A lo largo de este capítulo analizaremos las diferentes herramientas utilizadas para el desarrollo de este TFG, lo primero que se requiere es de un espacio donde facilitar la conexión entre los diferentes servicios web para ello utilizamos Django, la función principal de la que se encargan nuestros servicios web será todo lo relacionado con el uso del lenguaje natural, para ello se necesita un analizador del propio lenguaje como es Spacy y una vez analizado el lenguaje, es imprescindible un generador de frases de lenguaje natural en este caso el elegido es Simple-NLG, para conseguir las traducciones de texto a pictogramas ha sido imprescindible el uso de la API de Arasaac.\\     
Una parte importante en este proceso es conseguir una correcta comunicación entre los servicios web que utilizan lenguaje Java como por ejemplo los servicios web encargados de la traducción a lenguaje natural con otros basados en python, para asegurarnos de que esta comunicación se realiza correctamente es necesario la utilización de la librería GSON la cual es capaz de realizar la conversión de un objeto en lenguaje python a Java.\\  
Por último, para agilizar tanto el tiempo de respuesta de los servidores como el proceso de comunicación de los diferentes servicios web de nuestro trabajo se ha elegido la herramienta Angular.
  

%-------------------------------------------------------------
\section{Django}
%-------------------------------------------------------------
\label{cap3:sec:Django}
Debido a los diferentes servicios web que se utilizan en este TFG, se necesita un espacio o contenedor en donde pudieran desembocar y relacionar entre sí estos servicios mencionados anteriormente. Además al ser python uno de los lenguajes de programación más utilizados en el proyecto, era aconsejable que dicho contenedor estuviera también desarrollado en ese mismo lenguaje. 
Con estos requisitos previos se eligió la herramienta Django que al ser un framework de desarrollo web\footnote{https://tutorial.djangogirls.org/es/django/} de código abierto escrito en Python,  y respetando el patrón de diseño conocido como Modelo-Vista-Controlador (M-V-C). Tiene como meta principal facilitar la creación de sitios web. Además de ser muy importante el re-uso de código, la conectividad y el desarrollo rápido.\\
Todos estos motivos la convirtieron en la herramienta ideal sobre la que construir la comunicación entre los diferentes servicios y además al estar escrita en Python nos solucionaba problemas de errores con uno de los lenguajes de programación utilizados. 

\section{API-Arasaac}
%-------------------------------------------------------------
\label{cap3:sec:API-Arasaac}

Para conseguir la traducción de cada pictograma a texto hemos utilizado la API de Arasaac\footnote{https://beta.arasaac.org/developers/api}, centrándonos en la sección de pictogramas.
En este trabajo se han utilizado dos de los métodos proporcionados en la API, por un lado obtenemos la información del pictograma a partir de su id, con esto se consigue una relación entre la palabra y su pictograma gracias al código de identificación.
Por ejemplo si se desea buscar la palabra \textit{perro}, el método relaciona dicha palabra a su id devolviendo el pictograma asociado a ella, en este caso el id 2517.

El segundo método utilizado permite obtener el texto asociado a un pictograma partiendo de su id encontrado en el método anterior, gracias a esto  se logra una conexión entre el texto, su pictograma y un objeto con toda la información relevante asociada a la palabra , siguiendo el ejemplo anterior del pictograma con id 2517 se consigue una relación con el texto \textit{perro} y además un objeto con información relativa dicha palabra.  

\section{Spacy}
%-------------------------------------------------------------
\label{cap3:sec:Spacy}
Spacy es una biblioteca escrita en Python diseñada para el procesamiento avanzado de lenguaje natural\footnote{\url{https://medium.com/datos-y-ciencia/comenzando-con-spacy-para-procesamiento-de-lenguaje-natural-e8cf24a18a5a}}.

Para el uso del lenguaje natural primero se necesitaba realizar una clasificación y análisis de las palabras que se quieran traducir a pictogramas y así conocer las características de cada una de ellas. Para esta función de analizador se eligió usar la librería Spacy por delante de otras como NLTK, esta elección se basó sobre todo al estar Spacy orientado a objetos devolviendo la información necesaria en dicho objeto, mientras que NLTK es una biblioteca de procesamiento de cadenas, es decir, recibe como entrada una cadena y devuelve otra cadena. Por tanto era más adecuado para nuestro proyecto el uso de Spacy. 
    
Como acabo de mencionar en el párrafo anterior, Spacy será el encargado de proporcionarnos la información de los atributos de cada palabra analizada mediante su función Tokenizer. Así con esta función obtendremos la categoría léxica de las palabras, es decir, conseguiremos conocer si la palabra es sustantivo, adjetivo, verbo, determinante, etc.

Una vez conseguida su categoría léxica, Spacy nos proporciona las características de cada palabra y nosotros dependiendo del tipo de palabra que sea seleccionamos unos atributos u otros como son:
\begin{itemize}
    \item \textbf{Sustantivos} y \textbf{Adjetivos}, lo principal es conocer su género y número.
    \item \textbf{Verbos}, se obtiene su forma y tiempo verbal.
    \item \textbf{Determinantes}, es importante su número y el tipo de determinante.
    \item \textbf{Adverbios}, \textbf{Preposiciones} y demás complementos, solo interesa conocer su categoría léxica.
\end{itemize}
 
Toda esta información se mandará como entrada a la siguiente fase de nuestro TFG, la de generador del lenguaje.

\section{SimpleNLG-ES}
%-------------------------------------------------------------
\label{cap3:sec:SimpleNLG}
Una vez Spacy analiza y clasifica todas las partes de la oración. Se necesita una nueva herramienta que recibiendo como entrada una lista con el análisis pormenorizado de dicha oración e identificados el sujeto, verbo y complementos de la misma, sea capaz de generar cada palabra en lenguaje natural. 
La herramienta idónea elegida para realizar esta tarea es SimpleNLG-ES, esta biblioteca hecha en Java permite realizar la generación de lenguaje natural usando palabras\citep{Trzpis2015}.\\
Conforme los datos de entrada que reciba Simple-NLG es capaz de crear diferentes tipos de frases, yendo desde frases simples o frases nominales hasta aquellas que posean un cierto grado de complejidad como pueden ser frases más complejas u oraciones. Dependiendo la complejidad de la frase, su forma de realizar la generación de lenguaje natural difiere una de otra.
\begin{itemize}
    \item \textbf{Frases simples o nominales}. Cuando se ha identificado que la frase para analizar no tiene ningún verbo, Simple-NLG empieza a generar el sustantivo de la frase añadiendo a dicho sustantivo el determinante que concuerde con el género y número especificado en los datos de entrada en caso que fuera necesario. Una vez creado el sustantivo con su determinante correspondiente Simple-NLG iría generando los complementos que integran el sujeto completo, como pueden ser: adjetivos, adverbios, etc, por ejemplo para la frase ``La casa roja''. El sustantivo será ``casa'', su determinante asociado será ``la'' y por último el complemento del sustantivo será ``roja''.    
    \item \textbf{Frases compuestas u Oraciones}. Para este tipos de frases u oraciones lo primero que se busca es el verbo, una vez identificado dicho verbo, aquello que se encuentre delante de él formará el sujeto y el resto será el predicado con sus complementos, haciendo la generación del lenguaje en esta ocasión de la siguiente manera:
    \begin{itemize}
    \item Sujeto. Se genera de la misma forma que en las frases nominales, por ejemplo ``mi perro''.
    \item Verbo. Dependiendo de los datos de entrada recibidos, se obtiene la forma y el tiempo verbal, diferenciando entre pasado, futuro o presente, este último a su vez es el que viene por defecto. Y generando así la respuesta más adecuada, como por ejemplo ``es'' se generará como una oración en presente. 
    \item Complementos. Una vez generado el verbo se identifica si existen más datos en el predicado, en caso afirmativo se generan los elementos correspondientes, por ejemplo ``negro''. 
    \end{itemize}
\end{itemize}
Es importante destacar que Simple-NLG permite también negar las frases u oraciones, y además una vez se haya realizado la generación de la frase al completo, siguiendo el ejemplo dado, la frase generada en su totalidad será: ``mi perro es negro''. 
La misma herramienta se encargará de devolver la respuesta del servicio web gracias a la última fase llamada realización.   

\section{GSON}
%-------------------------------------------------------------
\label{cap3:sec:GSON}
Como hemos explicado en el apartado de la API de Arasaac, los pictogramas obtenidos vienen escritos en python pero nuestras herramientas para el tratamiento del lenguaje Natural utilizan lenguaje Java, por esta razón se necesita en este trabajo el uso de GSON.  
Es una librería open-source la cuál nos permite convertir nuestros objetos Java en JSON o viceversa, esta librería es muy importante ya que nos permite poder obtener un objeto GSON compatible con un servicio web configurado en lenguaje Java. Nuestro servicio web obliga a recibir un objeto en formato JSON.

Esta librería GSON contiene el método "from JSON", dicho método es vital para la obtención de un objeto compatible entre los servicios python y los de Java.

Una vez obtenido el objeto GSON mencionado, la propia librería se encarga de mandar el objeto al servicio web que lo necesita.
    
\section{Angular}
%-------------------------------------------------------------
\label{cap3:sec:Angular}
Angular es un framework de desarrollo creado y mantenido por Google, cuya finalidad consiste en el desarrollo de aplicaciones web SPA (Single-Page Applications), es decir, interacción web con una sola página web. Esta herramienta nos aporta tanto una mayor flexibilidad, como una mayor operabilidad en la parte del cliente, haciendo que dicha parte sea más rápida, dinámica y fluida.

Esta aportación es muy importante para nuestra aplicación ya que en la parte backend del servidor la herramienta Django explicada en el apartado anterior es la encargada de realizar todo el proceso, sin embargo para la parte frontend observamos que no disponíamos de ninguna herramienta que se encargara de ella, la cuál nos proporcionaría como he mencionado anteriormente una mayor fluidez y rapidez al servidor. Es ahí donde entra Angular siendo el encargado de la parte frontend haciendo cada parte de la página web independiente una de la otra.
  
Para realizar esta función de la parte frontend del servidor se estudiaron las diferentes herramientas que se podrían utilizar, en un primer momento se pensó en extender la herramienta Django para la parte del cliente, pero dicha herramienta ofrecía ciertas limitaciones en esta parte del servidor, por tanto se deshizo esa idea.
La segunda alternativa fue la opción de introducir JQuery, esta segunda opción era mejor que la primera aunque sin llegar a convencernos del todo.
La última opción y al final la escogida fue la de implantar dentro de nuestro trabajo Angular, ya que era la alternativa que más funcionalidades aportaba y la más completa.

Además la herramienta está formado por diferentes módulos distintos unos de otros y estos a su vez están formados por diferentes componentes, ofreciendo una división automática de códigos para que los usuarios solo carguen aquellos que necesitan.
Otra característica importante de Angular es que se desarrolla en el lenguaje TypeScript que es un lenguaje fuertemente tipado lo que ofrece beneficios sobre JavaScript, en el momento de la construcción del proyecto, el codigo TypeScript se convierte a JavaScript para poder utilizarlo en el navegador.

 


